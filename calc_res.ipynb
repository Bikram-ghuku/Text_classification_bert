{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c67ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ebce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dataAnalysis\\llm-classifier\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model.h5\", weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80173b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136060</th>\n",
       "      <td>[\"I have three oranges today, I ate an orange ...</td>\n",
       "      <td>[\"You have two oranges today.\"]</td>\n",
       "      <td>[\"You still have three oranges. Eating an oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211333</th>\n",
       "      <td>[\"You are a mediator in a heated political deb...</td>\n",
       "      <td>[\"Thank you for sharing the details of the sit...</td>\n",
       "      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233961</th>\n",
       "      <td>[\"How to initialize the classification head wh...</td>\n",
       "      <td>[\"When you want to initialize the classificati...</td>\n",
       "      <td>[\"To initialize the classification head when p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    prompt  \\\n",
       "id                                                           \n",
       "136060   [\"I have three oranges today, I ate an orange ...   \n",
       "211333   [\"You are a mediator in a heated political deb...   \n",
       "1233961  [\"How to initialize the classification head wh...   \n",
       "\n",
       "                                                response_a  \\\n",
       "id                                                           \n",
       "136060                     [\"You have two oranges today.\"]   \n",
       "211333   [\"Thank you for sharing the details of the sit...   \n",
       "1233961  [\"When you want to initialize the classificati...   \n",
       "\n",
       "                                                response_b  \n",
       "id                                                          \n",
       "136060   [\"You still have three oranges. Eating an oran...  \n",
       "211333   [\"Mr Reddy and Ms Blue both have valid points ...  \n",
       "1233961  [\"To initialize the classification head when p...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\", index_col = 0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6a3f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"prompt\"] = test.prompt.map(lambda x: eval(x)[0])\n",
    "test[\"response_a\"] = test.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test[\"response_b\"] = test.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c12e6bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>encode_fail</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136060</th>\n",
       "      <td>I have three oranges today, I ate an orange ye...</td>\n",
       "      <td>You have two oranges today.</td>\n",
       "      <td>You still have three oranges. Eating an orange...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: I have three oranges today, I ate an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211333</th>\n",
       "      <td>You are a mediator in a heated political debat...</td>\n",
       "      <td>Thank you for sharing the details of the situa...</td>\n",
       "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: You are a mediator in a heated politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233961</th>\n",
       "      <td>How to initialize the classification head when...</td>\n",
       "      <td>When you want to initialize the classification...</td>\n",
       "      <td>To initialize the classification head when per...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Prompt: How to initialize the classification ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    prompt  \\\n",
       "id                                                           \n",
       "136060   I have three oranges today, I ate an orange ye...   \n",
       "211333   You are a mediator in a heated political debat...   \n",
       "1233961  How to initialize the classification head when...   \n",
       "\n",
       "                                                response_a  \\\n",
       "id                                                           \n",
       "136060                         You have two oranges today.   \n",
       "211333   Thank you for sharing the details of the situa...   \n",
       "1233961  When you want to initialize the classification...   \n",
       "\n",
       "                                                response_b  encode_fail  \\\n",
       "id                                                                        \n",
       "136060   You still have three oranges. Eating an orange...        False   \n",
       "211333   Mr Reddy and Ms Blue both have valid points in...        False   \n",
       "1233961  To initialize the classification head when per...        False   \n",
       "\n",
       "                                                   options  \n",
       "id                                                          \n",
       "136060   [Prompt: I have three oranges today, I ate an ...  \n",
       "211333   [Prompt: You are a mediator in a heated politi...  \n",
       "1233961  [Prompt: How to initialize the classification ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except Exception:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except Exception:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except Exception:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"\n",
    "                     ]\n",
    "    return row\n",
    "\n",
    "test = test.apply(make_pairs, axis=1)  \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88e1d59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "599e384e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136060</th>\n",
       "      <td>[Prompt: I have three oranges today, I ate an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211333</th>\n",
       "      <td>[Prompt: You are a mediator in a heated politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233961</th>\n",
       "      <td>[Prompt: How to initialize the classification ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   options\n",
       "id                                                        \n",
       "136060   [Prompt: I have three oranges today, I ate an ...\n",
       "211333   [Prompt: You are a mediator in a heated politi...\n",
       "1233961  [Prompt: How to initialize the classification ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['prompt', 'response_b', 'response_a', 'encode_fail'], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "399ff367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\\n\\nResponse: You have two oranges today.', 'Prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have?\\n\\nResponse: You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.']),\n",
       "       list([\"Prompt: You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he\\\\/him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground.\\n\\nResponse: Thank you for sharing the details of the situation. As a mediator, I understand the importance of finding a middle ground that both parties can agree upon.\\n\\nIt is important to recognize that language and definitions can be complex and can vary depending on cultural and societal norms. At the same time, it is also important to acknowledge the biological differences between males and females.\\n\\nOne possible approach to finding a middle ground could be to focus on respecting individuals' self-identification and autonomy while also acknowledging the biological differences between males and females. This could involve using inclusive language that reflects individuals' gender identities while also recognizing the importance of biological sex in certain contexts, such as medical treatment and reproductive health.\\n\\nIt may also be helpful to explore ways to create a more inclusive society where individuals of all gender identities are valued and respected. This could involve promoting education and awareness about gender diversity and creating policies and practices that support individuals' gender identities and expression.\\n\\nUltimately, the goal of mediation is to find a solution that meets the needs and concerns of both parties. By focusing on mutual respect, open communication, and a willingness to find common ground, it is possible to reach a resolution that allows both parties to move forward in a positive and productive way.\", \"Prompt: You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he\\\\/him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground.\\n\\nResponse: Mr Reddy and Ms Blue both have valid points in their arguments. On one hand, Mr Reddy is correct that women are adult human females, as defined by their biological and physical characteristics. However, Ms Blue is right that gender is a more fluid concept and that people can identify with any gender they choose. A compromise could be that gender is defined by an individual's self-identification, while sex is defined by their biological characteristics.\"]),\n",
       "       list([\"Prompt: How to initialize the classification head when I do transfer learning. For example, I have a pre-trained vision transformer on ImageNet, and now I want to finetune it on StanfordCars\\n\\nResponse: When you want to initialize the classification head for transfer learning, you can follow these steps:\\n\\n  1. Load the pre-trained model: First, load the pre-trained vision transformer model on ImageNet. You can use popular deep learning libraries like PyTorch or TensorFlow to load the model.\\n  2. Freeze the pre-trained layers: Next, you need to freeze the pre-trained layers of the model so that they don't get updated during the training process. This is because the pre-trained layers have learned useful features that can be reused for the new task.\\n  3. Add a new classification head: Now, you need to add a new classification head to the model. The classification head is responsible for outputting the predicted class for a given input image. The size of the classification head depends on the number of classes in the new task. For example, if you are working on the StanfordCars dataset, which has 196 classes, you would need a classification head with 196 output neurons.\\n  4. Initialize the classification head: Initialize the weights of the classification head randomly or using pre-trained weights. This is important because the initial weights can have a significant impact on the performance of the model.\\n  5. Train the model: Finally, you can train the model on the new task using your labeled data. During training, only the weights of the classification head will be updated, while the weights of the frozen pre-trained layers will remain unchanged. This allows the model to learn task-specific features while leveraging the pre-trained features.\\n\\nNote that there are different ways to initialize the classification head, such as using Xavier initialization, Kaiming initialization, or He initialization. You can choose the initialization method that works best for your specific task and model architecture.\", \"Prompt: How to initialize the classification head when I do transfer learning. For example, I have a pre-trained vision transformer on ImageNet, and now I want to finetune it on StanfordCars\\n\\nResponse: To initialize the classification head when performing transfer learning, follow these steps:\\n\\n1. Load the pre-trained vision transformer model that was trained on ImageNet.\\n2. Replace the existing classification head with a new one suitable for the StanfordCars dataset.\\n3. Initialize the weights of the new classification head with random values or pre-trained weights if available.\\n4. Freeze the weights of the vision transformer backbone to prevent them from being updated during training.\\n5. Train the model on the StanfordCars dataset, fine-tuning the classification head while keeping the backbone frozen.\\n\\nHere's an example implementation in Python using PyTorch:\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\n\\n# Step 1: Load pre-trained vision transformer model\\nvision_transformer = models.vit_base_patch16_224(pretrained=True)\\n\\n# Step 2: Replace classification head\\nnum_classes = 196  # Number of classes in StanfordCars dataset\\nvision_transformer.head = nn.Linear(vision_transformer.head.in_features, num_classes)\\n\\n# Step 3: Initialize weights of new classification head\\nnn.init.xavier_uniform_(vision_transformer.head.weight)\\nnn.init.constant_(vision_transformer.head.bias, 0)\\n\\n# Step 4: Freeze the weights of the backbone\\nfor param in vision_transformer.parameters():\\n    param.requires_grad = False\\n\\n# Step 5: Train the model on StanfordCars dataset\\n# ...\\n```\\n\\nIn this example, we load the pre-trained vision transformer model using `torchvision.models.vit_base_patch16_224`. We then replace the `head` (classification head) of the model with a new linear layer (`nn.Linear`) that has the appropriate number of output classes for the StanfordCars dataset.\\n\\nAfter replacing the classification head, we initialize its weights using Xavier initialization (`nn.init.xavier_uniform_`) and set its biases to zero (`nn.init.constant_`).\\n\\nFinally, we freeze the weights of the vision transformer backbone by setting `requires_grad=False` for all parameters. This ensures that only the weights of the classification head will be updated during training on the StanfordCars dataset.\"])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['options'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "758e1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18dc24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, dataSet: pd.DataFrame, tokenizer):\n",
    "        self.values = dataSet['options'].values\n",
    "        self.dataSet = dataSet\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.values[index]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=256,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = torch.reshape(encoding['input_ids'], (-1, ))\n",
    "        attention_mask = torch.reshape(encoding['attention_mask'], (-1, ))\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91f2e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataSet = TextClassificationDataset(test, tokenizer)\n",
    "test_loader = DataLoader(test_dataSet, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d832703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.30991364, 0.45228857, 0.23779777], dtype=float32),\n",
       " array([0.16487609, 0.6027802 , 0.23234364], dtype=float32),\n",
       " array([0.1631489 , 0.62330884, 0.21354225], dtype=float32)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "res = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        res.append(probs.cpu().numpy()[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d5d36789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309914</td>\n",
       "      <td>0.452289</td>\n",
       "      <td>0.237798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164876</td>\n",
       "      <td>0.602780</td>\n",
       "      <td>0.232344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163149</td>\n",
       "      <td>0.623309</td>\n",
       "      <td>0.213542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner_model_a  winner_model_b  winner_tie\n",
       "0        0.309914        0.452289    0.237798\n",
       "1        0.164876        0.602780    0.232344\n",
       "2        0.163149        0.623309    0.213542"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2f47b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['winner_model_a'] = df['winner_model_a']\n",
    "submission['winner_model_b'] = df['winner_model_b']\n",
    "submission['winner_tie'] = df['winner_tie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f360f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88d65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
